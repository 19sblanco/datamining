import pandas as pd
import random as r
import sys
from sklearn.feature_extraction.text import CountVectorizer 


seeds = [2387, 7529, 7454, 2864, 6440, 5731, 7103, 8305, 1802, 8732, 1988, 1314, 7471, 4316, 785, 3351, 5495, 3764, 5070, 3341, 2924, 2308, 3090, 5686, 6064, 6713, 3455, 6604, 7555, 9100, 4519, 6146, 2629, 2034, 2960, 93, 9876, 6481, 2419, 9276, 2664, 3157, 2737, 429, 3887, 7344, 6352, 2075, 9076, 860, 9980, 4049, 8309, 4749, 9673, 5550, 8654, 5625, 8888, 5948, 7923, 6583, 1015, 1661, 4914, 7119, 4138, 3929, 7167, 8415, 8086, 9547, 4165, 2412, 954, 9591, 5354, 2699, 895, 4509, 1983, 832, 9755, 3591, 5077, 8594, 3547, 9310, 5853, 5469, 7467, 206, 1869, 7791, 3160, 8607, 1952, 9760, 3427, 720, 6388, 1705, 6564, 2483, 7811, 8931, 637, 7295, 2640, 809, 7764, 772, 3247, 4077, 2580, 1546, 640, 2294, 3469, 1478, 2016, 4123, 1095, 6587, 604, 8857, 6985, 7769, 7382, 5631, 7442, 8579, 3182, 9937, 9499, 4116, 6845, 2382, 3420, 6763, 1269, 9796, 4408, 6567, 4268, 1556, 3121, 3730, 776, 6399, 4447, 47, 4445, 4989, 619, 428, 9150, 4826, 3801, 6598, 160, 1311, 3600, 4883, 378, 1423, 9588, 5778, 5310, 7280, 553, 3020, 1372, 375, 5775, 9075, 2354, 2605, 53, 224, 5240, 8313, 6494, 2859, 6236, 6262, 7318, 3202, 3483, 2638, 9848, 9446, 9005, 4437, 1199, 7496, 2230, 7168, 9579, 9575, 8266, 1820, 4929, 2061, 1824, 9488, 3656, 773, 6448, 7511, 7046, 5759, 1433, 1138, 765, 7235, 6820, 328, 9273, 2529, 7875, 1741, 1451, 4813, 1565, 9094, 9285, 2409, 2302, 9088, 9572, 2404, 2789, 5868, 9269, 6217, 1707, 7937, 5294, 1901, 7734, 4613, 3717, 5707, 3751, 574, 233, 3684, 8301, 1852, 8979, 1457, 2049, 7691, 854, 7833, 5737, 8367, 7823, 3335, 8068, 779, 8295, 9636, 4195, 481, 9911, 8608, 8587, 1750, 3012, 649, 9476, 3813, 7587, 180, 1865, 3650, 6015, 5260, 1968, 4917, 1700, 5021, 4997, 7170, 3146, 5334, 1447, 2566, 5624, 9779, 2515, 3146, 6944, 1342, 1435, 5163, 9894, 3338, 5152, 4387, 2499, 1815, 7269, 262, 3352, 8507, 2659, 7739, 9824, 691, 8887, 7234, 5743, 120, 1363, 8146, 996, 6968, 6251, 2542, 3185, 7142, 2956, 3359, 4358, 4152, 3564, 4816, 6559, 6422, 4257, 5472, 451, 4361, 3946, 8510, 2885, 860, 6816, 1522, 5774, 1962, 2778, 7740, 6067, 3505, 8490, 3909, 6616, 353, 7642, 5527, 641, 4338, 8175, 9776, 810, 1217, 5825, 681, 4231, 9528, 7502, 9427, 4729, 8746, 6516, 5960, 5318, 2578, 2067, 3009, 5569, 8082, 6550, 6695, 4046, 8178, 1600, 8694, 3464, 2894, 1262, 4025, 1323, 311, 4586, 7906, 3591, 5489, 6663, 745, 9758, 4475, 7802, 5639, 5621, 1191, 8342, 4717, 2594, 6135, 5062, 3825, 6610, 7117, 649, 75, 4415, 1336, 8772, 1617, 4514, 6939, 7851, 8733, 4553, 9060, 701, 8124, 5100, 2988, 1414, 1488, 8039, 3420, 8678, 1398, 5552, 2552, 6653, 8296, 650, 6480, 5436, 6661, 2908, 9219, 7110, 4056, 9879, 1317, 7371, 6033, 26, 4721, 6940, 154, 7384, 9831, 4710, 3241, 7339, 8016, 8662, 2058, 7746, 2307, 3361, 4694, 6381, 149, 410, 6571, 1815, 9457, 3981, 2344, 3936, 7760, 2834, 6718, 5068, 4863, 8593, 6366, 6300, 6376, 9426, 7768, 1902, 9145, 9350, 2290, 528, 8358, 955, 335, 8335, 7014, 6349, 6262, 3627, 333, 1858, 1220, 3661, 6240, 4378, 5076, 8506, 2667, 7827, 9065, 6009, 5697, 5738, 6681, 4562, 1212, 6917, 3805, 6342, 7, 4766, 8896, 557, 6107, 7869, 6748, 4169, 7181, 2262, 8101, 9741, 5885, 4782, 186, 1255, 6414, 2012, 8551, 6537, 3437, 2643, 4425, 814, 650, 1518, 8646, 7380, 5648, 421, 5705, 9673, 3305, 5439, 4028, 9409, 4838, 8489, 4700, 5167, 5256, 5131, 4351, 1676, 2569, 5089, 7241, 8316, 3823, 3832, 3964, 5528, 2401, 6497, 7714, 7671, 2322, 6603, 5779, 2824, 3981, 3764, 4655, 4658, 7941, 4911, 9199, 9668, 4595, 9476, 5548, 502, 6249, 6320, 9186, 6980, 7897, 4642, 8449, 6684, 457, 8604, 6631, 2316, 5378]
t_list = [20, 60, 150, 300, 600]

def mod_hash(x, m, seed):
    hash = (x * seed) % m
    return hash

def get_ascii(string):
    value = 0
    for c in range(len(string)):
        value += ord(string[c]) * (c*10)
    return value

def convert_to_nums(n_grams):
    nums = []
    for n_gram in n_grams:
        num = get_ascii(n_gram)
        nums.append(num)
    return nums

def intersection(ls1, ls2):
    new_list = []
    for item in ls1:
        if item in ls2:
            new_list.append(item)
    return new_list

def set_minus(ls1, ls2):
    new_list = []
    for item in ls1:
        if item not in ls2:
            new_list.append(item)
    return new_list

def union(ls1, ls2):
    new_list = []
    for item in ls1:
        new_list.append(item)

    for item in ls2:
        if item not in ls1:
            new_list.append(item)
    return new_list

def same_elem(ls1, ls2):
    for item in ls1:
        if item not in ls2:
            return False
    for item in ls2:
        if item not in ls1:
            return False
    return True


def jaccard(x, y):
    top = len(intersection(x, y))
    bottom = len(intersection(x, y)) + len(set_minus(union(x, y), intersection(x, y)))
    return top / bottom



# D1 = [open("D1.txt", "r").read()]
# D2 = [open("D2.txt", "r").read()]

D1 = [open("dm1.txt", "r").read()]
D2 = [open("dm2.txt", "r").read()]

m = [0] * 10_000

vectorizer = CountVectorizer(analyzer="char", ngram_range=(3,3))
x = vectorizer.fit_transform(D1)
d1_3grams = vectorizer.get_feature_names()
y = vectorizer.fit_transform(D2)
d2_3grams = vectorizer.get_feature_names()

s1 = convert_to_nums(d1_3grams)
s2 = convert_to_nums(d2_3grams)

print("actual", jaccard(s1, s2))


s_list = [s1, s2]


for t in t_list: # number of hash functions used
    x = []
    y = []

    for s in range(len(s_list)): # for each set
        v = [sys.maxsize] * t
        # for s in set: # for each element of the set
        for s_i in range(len(s_list[s])):
            if s_i == 17:
                pass

            for i in range(t): # for each hash function
                temp = mod_hash(s_list[s][s_i], len(m), seeds[i])
                if (temp < v[i]):
                    v[i] = temp

        if s == 0: # store signiture for set 1
            x = v
            print(x)
            exit()
        elif s == 1: # store signiture for set 2 then print if the equal
            y = v
            js = jaccard(x, y)
            print("#hash: ", t, " ", js)

            












